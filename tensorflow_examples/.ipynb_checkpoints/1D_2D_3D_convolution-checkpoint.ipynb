{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About:\n",
    "This notebook discusses about 1D,2D, 3D convolution operations in tensorflow. These would be used in a CNN layer. Most of these codes are taken from stackoverflow posts like [this](https://stackoverflow.com/questions/42883547/what-do-you-mean-by-1d-2d-and-3d-convolutions-in-cnn) and [this](https://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T16:22:16.061559Z",
     "start_time": "2017-08-12T16:22:14.350505Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:34:09.628394Z",
     "start_time": "2017-08-12T19:34:09.619781Z"
    }
   },
   "source": [
    "## 1D convolution\n",
    "- just 1-direction (time-axis) to calculate conv\n",
    "- input = [W], filter = [k], output = [W]\n",
    "- output-shape is 1D array\n",
    "- example) graph smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:40:32.918713Z",
     "start_time": "2017-08-12T19:40:32.817495Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "ones_1d = np.ones(5)\n",
    "weight_1d = np.ones(3)\n",
    "strides_1d = 1\n",
    "\n",
    "in_1d = tf.constant(ones_1d, dtype=tf.float32)\n",
    "filter_1d = tf.constant(weight_1d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_1d.shape[0])\n",
    "filter_width = int(filter_1d.shape[0])\n",
    "\n",
    "input_1d   = tf.reshape(in_1d, [1, in_width, 1])\n",
    "kernel_1d = tf.reshape(filter_1d, [filter_width, 1, 1])\n",
    "output_1d = tf.squeeze(tf.nn.conv1d(input_1d, kernel_1d, strides_1d, padding='SAME'))\n",
    "print (sess.run(output_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D convolution\n",
    "- 2-direction (x,y) to calculate conv\n",
    "- output-shape is 2D Matrix\n",
    "- input = [W, H], filter = [k,k] output = [W,H]\n",
    "- example) Sobel Egde Fllter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:32:31.530076Z",
     "start_time": "2017-08-12T19:32:31.460169Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of a 2D convolution\n",
    "ones_2d = np.ones((5,5))\n",
    "weight_2d = np.ones((3,3))\n",
    "strides_2d = [1, 1, 1, 1]\n",
    "\n",
    "in_2d = tf.constant(ones_2d, dtype=tf.float32)\n",
    "filter_2d = tf.constant(weight_2d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_2d.shape[0])\n",
    "in_height = int(in_2d.shape[1])\n",
    "\n",
    "filter_width = int(filter_2d.shape[0])\n",
    "filter_height = int(filter_2d.shape[1])\n",
    "\n",
    "input_2d   = tf.reshape(in_2d, [1, in_height, in_width, 1])\n",
    "kernel_2d = tf.reshape(filter_2d, [filter_height, filter_width, 1, 1])\n",
    "\n",
    "output_2d = tf.squeeze(tf.nn.conv2d(input_2d, kernel_2d, strides=strides_2d, padding='SAME'))\n",
    "print (sess.run(output_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:35:42.930267Z",
     "start_time": "2017-08-12T19:35:42.917769Z"
    }
   },
   "source": [
    "## 3D convolution\n",
    "- 3-direction (x,y,z) to calcuate conv\n",
    "- output-shape is 3D Volume\n",
    "- input = [W,H,L], filter = [k,k,d] output = [W,H,M]\n",
    "- d < L is important! for making volume output\n",
    "- example) C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:36:04.906395Z",
     "start_time": "2017-08-12T19:36:04.769797Z"
    }
   },
   "outputs": [],
   "source": [
    "ones_3d = np.ones((5,5,5))\n",
    "weight_3d = np.ones((3,3,3))\n",
    "strides_3d = [1, 1, 1, 1, 1]\n",
    "\n",
    "in_3d = tf.constant(ones_3d, dtype=tf.float32)\n",
    "filter_3d = tf.constant(weight_3d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_3d.shape[0])\n",
    "in_height = int(in_3d.shape[1])\n",
    "in_depth = int(in_3d.shape[2])\n",
    "\n",
    "filter_width = int(filter_3d.shape[0])\n",
    "filter_height = int(filter_3d.shape[1])\n",
    "filter_depth = int(filter_3d.shape[2])\n",
    "\n",
    "input_3d   = tf.reshape(in_3d, [1, in_depth, in_height, in_depth, 1])\n",
    "kernel_3d = tf.reshape(filter_3d, [filter_depth, filter_height, filter_width, 1, 1])\n",
    "\n",
    "output_3d = tf.squeeze(tf.nn.conv3d(input_3d, kernel_3d, strides=strides_3d, padding='SAME'))\n",
    "print (sess.run(output_3d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolutions with 3D input - LeNet, VGG, etc\n",
    "- Eventhough input is 3D ex) 224x224x3, 112x112x32\n",
    "- output-shape is not 3D Volume, but 2D Matrix\n",
    "- because filter depth = L must be matched with input channels = L\n",
    "- 2-direction (x,y) to calcuate conv! not 3D\n",
    "- input = [W,H,L], filter = [k,k,L] output = [W,H]\n",
    "- output-shape is 2D Matrix\n",
    "- what if we want to train N filters (N is number of filters) then output shape is (stacked 2D) 3D = 2D x N matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:37:41.948151Z",
     "start_time": "2017-08-12T19:37:41.902475Z"
    }
   },
   "outputs": [],
   "source": [
    "in_channels = 32 # 3 for RGB, 32, 64, 128, ... \n",
    "ones_3d = np.ones((5,5,in_channels)) # input is 3d, in_channels = 32\n",
    "# filter must have 3d-shpae with in_channels\n",
    "weight_3d = np.ones((3,3,in_channels)) \n",
    "strides_2d = [1, 1, 1, 1]\n",
    "\n",
    "in_3d = tf.constant(ones_3d, dtype=tf.float32)\n",
    "filter_3d = tf.constant(weight_3d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_3d.shape[0])\n",
    "in_height = int(in_3d.shape[1])\n",
    "\n",
    "filter_width = int(filter_3d.shape[0])\n",
    "filter_height = int(filter_3d.shape[1])\n",
    "\n",
    "input_3d   = tf.reshape(in_3d, [1, in_height, in_width, in_channels])\n",
    "kernel_3d = tf.reshape(filter_3d, [filter_height, filter_width, in_channels, 1])\n",
    "\n",
    "output_2d = tf.squeeze(tf.nn.conv2d(input_3d, kernel_3d, strides=strides_2d, padding='SAME'))\n",
    "print (sess.run(output_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:38:00.128326Z",
     "start_time": "2017-08-12T19:38:00.125142Z"
    }
   },
   "source": [
    "## conv2d - LeNet, VGG, ... for N filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:38:25.006259Z",
     "start_time": "2017-08-12T19:38:24.957178Z"
    }
   },
   "outputs": [],
   "source": [
    "in_channels = 32 # 3 for RGB, 32, 64, 128, ... \n",
    "out_channels = 64 # 128, 256, ...\n",
    "ones_3d = np.ones((5,5,in_channels)) # input is 3d, in_channels = 32\n",
    "# filter must have 3d-shpae x number of filters = 4D\n",
    "weight_4d = np.ones((3,3,in_channels, out_channels))\n",
    "strides_2d = [1, 1, 1, 1]\n",
    "\n",
    "in_3d = tf.constant(ones_3d, dtype=tf.float32)\n",
    "filter_4d = tf.constant(weight_4d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_3d.shape[0])\n",
    "in_height = int(in_3d.shape[1])\n",
    "\n",
    "filter_width = int(filter_4d.shape[0])\n",
    "filter_height = int(filter_4d.shape[1])\n",
    "\n",
    "input_3d   = tf.reshape(in_3d, [1, in_height, in_width, in_channels])\n",
    "kernel_4d = tf.reshape(filter_4d, [filter_height, filter_width, in_channels, out_channels])\n",
    "\n",
    "#output stacked shape is 3D = 2D x N matrix\n",
    "output_3d = tf.nn.conv2d(input_3d, kernel_4d, strides=strides_2d, padding='SAME')\n",
    "print (sess.run(output_3d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1x1 conv in CNN - GoogLeNet, .. etc\n",
    "- 1x1 conv is confusing when you think this as 2D image filter like sobel\n",
    "- for 1x1 conv in CNN, input is 3D shape as above picture.\n",
    "- it calculate depth-wise filtering\n",
    "- input = [W,H,L], filter = [1,1,L] output = [W,H]\n",
    "- output stacked shape is 3D = 2D x N matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:39:36.948549Z",
     "start_time": "2017-08-12T19:39:36.904121Z"
    }
   },
   "outputs": [],
   "source": [
    "in_channels = 32 # 3 for RGB, 32, 64, 128, ... \n",
    "out_channels = 64 # 128, 256, ...\n",
    "ones_3d = np.ones((1,1,in_channels)) # input is 3d, in_channels = 32\n",
    "# filter must have 3d-shpae x number of filters = 4D\n",
    "weight_4d = np.ones((3,3,in_channels, out_channels))\n",
    "strides_2d = [1, 1, 1, 1]\n",
    "\n",
    "in_3d = tf.constant(ones_3d, dtype=tf.float32)\n",
    "filter_4d = tf.constant(weight_4d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_3d.shape[0])\n",
    "in_height = int(in_3d.shape[1])\n",
    "\n",
    "filter_width = int(filter_4d.shape[0])\n",
    "filter_height = int(filter_4d.shape[1])\n",
    "\n",
    "input_3d   = tf.reshape(in_3d, [1, in_height, in_width, in_channels])\n",
    "kernel_4d = tf.reshape(filter_4d, [filter_height, filter_width, in_channels, out_channels])\n",
    "\n",
    "#output stacked shape is 3D = 2D x N matrix\n",
    "output_3d = tf.nn.conv2d(input_3d, kernel_4d, strides=strides_2d, padding='SAME')\n",
    "print (sess.run(output_3d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Some other simple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this simple case the resulting 2x2, 1 channel image (size 1x2x2x1, number of images x height x width x x channels) is the \n",
    "result of multiplying the filter value by each pixel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:31:06.840995Z",
     "start_time": "2017-08-12T19:31:06.786608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = tf.Variable(tf.random_normal([1,3,3,5]))\n",
    "filter = tf.Variable(tf.random_normal([1,1,5,1]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try more channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T19:31:08.064646Z",
     "start_time": "2017-08-12T19:31:08.031181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = tf.Variable(tf.random_normal([1,3,3,5]))\n",
    "filter = tf.Variable(tf.random_normal([1,1,5,1]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "keras_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
